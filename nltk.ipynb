{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/darkospy/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\\\n",
    "Here are five creative ideas for repurposing your kids' art and reducing clutter:\n",
    "\n",
    "Create a Memory Book: Compile their artwork into a scrapbook or photo album. This way, you can preserve their artistic journey over the years in a neat and organized manner.\n",
    "\n",
    "DIY Wall Art: Select some of the best pieces and frame them to create unique wall art for your home. This way, you can showcase their creations while adding a personalized touch to your decor.\n",
    "\n",
    "Custom Gift Wrap: Use their art to create custom gift wrap for special occasions. Simply wrap presents in their drawings and paintings for a heartfelt and one-of-a-kind touch.\n",
    "\n",
    "Collage or Mosaic: Cut or tear the artwork into smaller pieces and create collages or mosaics. This is a great way to make new artworks while incorporating their original creations.\n",
    "\n",
    "Turn Art into Accessories: Transform their art into wearable accessories like jewelry or keychains. There are online services that can turn drawings into pendants, pins, or even temporary tattoos.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Sentence Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This way, you can preserve their artistic journey over the years in a neat and organized manner.\n"
     ]
    }
   ],
   "source": [
    "# split the text into sentences\n",
    "sentences = sent_tokenize(text)\n",
    "print(sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This way  you can preserve their artistic journey over the years in a neat and organized manner \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "new_text = re.sub(r\"[^a-zA-Z0-9]\", \" \", sentences[1])\n",
    "print(new_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'way', 'you', 'can', 'preserve', 'their', 'artistic', 'journey', 'over', 'the', 'years', 'in', 'a', 'neat', 'and', 'organized', 'manner']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "tokenized_words = word_tokenize(new_text)\n",
    "print(tokenized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words removel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'way', 'preserve', 'artistic', 'journey', 'years', 'neat', 'organized', 'manner']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/darkospy/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "without_stopwords = [word for word in tokenized_words if word not in stopwords.words(\"english\")]\n",
    "print(without_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'way', 'preserv', 'artist', 'journey', 'year', 'neat', 'organ', 'manner']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "sn_stemmer = SnowballStemmer(\"english\")\n",
    "stemmed_words = [sn_stemmer.stem(w) for w in without_stopwords]\n",
    "print(stemmed_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/darkospy/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/darkospy/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['This', 'way', 'preserve', 'artistic', 'journey', 'year', 'neat', 'organized', 'manner']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [lemmatizer.lemmatize(w) for w in without_stopwords]\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/darkospy/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /Users/darkospy/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('This', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('preserve', 'VB'),\n",
       " ('artistic', 'JJ'),\n",
       " ('journey', 'NN'),\n",
       " ('years', 'NNS'),\n",
       " ('neat', 'RB'),\n",
       " ('organized', 'VBD'),\n",
       " ('manner', 'NN')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "from nltk import pos_tag\n",
    "pos_tag(without_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Name Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  The/DT\n",
      "  two/CD\n",
      "  billionaires/NNS\n",
      "  '/POS\n",
      "  business/NN\n",
      "  interests/NNS\n",
      "  have/VBP\n",
      "  butted/VBN\n",
      "  heads/NNS\n",
      "  in/IN\n",
      "  the/DT\n",
      "  past/NN\n",
      "  :/:\n",
      "  (PERSON Musk/NN)\n",
      "  's/POS\n",
      "  2016/CD\n",
      "  test/NN\n",
      "  launch/NN\n",
      "  of/IN\n",
      "  a/DT\n",
      "  (ORGANIZATION SpaceX/NNP)\n",
      "  rocket/NN\n",
      "  destroyed/VBD\n",
      "  (PERSON Zuckerberg/NNP)\n",
      "  's/POS\n",
      "  (ORGANIZATION US/NNP)\n",
      "  $/$\n",
      "  200/CD\n",
      "  million/CD\n",
      "  satellite/NN\n",
      "  ./.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/darkospy/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "nltk.download('words')\n",
    "ner_tree = ne_chunk(pos_tag(word_tokenize(\"The two billionaires' business interests have butted heads in the past: Musk's 2016 test launch of a SpaceX rocket destroyed Zuckerberg's US$200 million satellite.\")))\n",
    "print(ner_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
